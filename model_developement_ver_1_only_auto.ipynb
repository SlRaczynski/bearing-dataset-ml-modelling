{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of the project is to develop ml model for Remaining Useful Life (RUL) prediction based on NASA Bering dataset from Kaggle platform. Check data/sources.txt for data and feature engineering and selection ideas. The final result is in form of sklearn pipeline. The RUL is in form of remaining rotations (not time).\n",
    "\n",
    "In this analysis only feature extraction is performed for feature engineering activities. Rest of the feature selection, scaling, etc. activities are to be handled by AutoML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data preparation - feature extraction\n",
    "\n",
    "Because only some of the data repersent bearings that failed only this part of the data will be used in model developement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Feature and labels extraction from dataset and save to separate file to avoid recalculation each run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from feature_extraction.feature_extraction import extract_features\n",
    "\n",
    "directories_list = ['data/1st_test/1st_test', 'data/2nd_test/2nd_test', 'data/3rd_test/4th_test/txt']\n",
    "columns_indices_list = [[4,5,6,7], [0], [2]]\n",
    "time_format = r'%Y.%m.%d.%H.%M.%S'\n",
    "sampling_freq = 20000\n",
    "sampling_time = 1\n",
    "shaft_rpm = 2000\n",
    "\n",
    "bearing_properties = {'roll_elem_diam'  : 0.331,\n",
    "                      'pitch_diam'      : 2.815,\n",
    "                      'roll_elem_count' : 16,\n",
    "                      'contact_angle'   : 15.17}\n",
    "\n",
    "rul_rotations_df_list = []\n",
    "time_df_list = []\n",
    "orders_df_list = []\n",
    "\n",
    "for directory, column_indices in zip(directories_list, columns_indices_list):\n",
    "    rul_rotations, time_features, orders_features = extract_features(directory, column_indices, time_format, sampling_freq, sampling_time, shaft_rpm, bearing_properties['roll_elem_diam'], bearing_properties['pitch_diam'], bearing_properties['roll_elem_count'], bearing_properties['contact_angle'])\n",
    "    rul_rotations_df_list.append(rul_rotations)\n",
    "    time_df_list.append(time_features)\n",
    "    orders_df_list.append(orders_features)\n",
    "\n",
    "cummulated_rul_rotations_df = pd.concat(rul_rotations_df_list, ignore_index=True, axis=0)\n",
    "cummulated_time_features_df = pd.concat(time_df_list, ignore_index=True, axis=0)\n",
    "cummulated_orders_features_df = pd.concat(orders_df_list, ignore_index=True, axis=0)\n",
    "\n",
    "extracted_data = pd.concat((cummulated_rul_rotations_df, cummulated_time_features_df, cummulated_orders_features_df), axis=1)\n",
    "extracted_data.to_csv('extracted_data', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "extracted_data = pd.read_csv('extracted_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Preparation of train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw = extracted_data['RUL_rotations']\n",
    "X_raw = extracted_data.drop('RUL_rotations', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_raw, y_raw, test_size=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Definition of custom scorer. Motivation is as following: the prediction should not deviate from real value more than 5% for 95% of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def custom_scorer_fn(y, y_pred, **kwargs):\n",
    "    error = y - y_pred\n",
    "    relative_error = error / y\n",
    "    abs_relative_error = np.abs(relative_error)\n",
    "    model_error = np.percentile(abs_relative_error, 95)\n",
    "    return model_error\n",
    "\n",
    "custom_scorer = make_scorer(custom_scorer_fn, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Training using AutoML library - TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tpot import TPOTRegressor\n",
    "\n",
    "new_cv = KFold(n_splits=9, shuffle=True, random_state=42)\n",
    "\n",
    "tpotregr = TPOTRegressor(scoring=custom_scorer, cv=new_cv, n_jobs=10, max_time_mins=720, random_state=21, warm_start=True, early_stop=100)\n",
    "tpotregr.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpotregr.export('rul_tpot_pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Retraining of model on all training data (no cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from tpot.builtins import StackingEstimator\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ExtraTreesRegressor(bootstrap=False, max_features=1.0, min_samples_leaf=7, min_samples_split=3, n_estimators=100)),\n",
    "    XGBRegressor(learning_rate=0.01, max_depth=10, min_child_weight=5, n_estimators=100, n_jobs=-1, objective=\"reg:squarederror\", subsample=0.3, verbosity=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Analysis of model performance\n",
    "\n",
    "The measures of performance will be:\n",
    "1. result of the custom scoring function o\n",
    "2. signed prediction error as percentage of remaining useful life"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 Custom scoring function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_pred = pipeline.predict(X_test)\n",
    "y_test = y_test.values.ravel()\n",
    "custom_scorer_fn(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 Signed prediction error as percentage of remaining useful life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = y_test - y_pred\n",
    "relative_error = error / y_test\n",
    "relative_error[np.isinf(relative_error)] = np.nan\n",
    "relative_error_percentage = relative_error * 100\n",
    "\n",
    "indices = np.argsort(y_test)\n",
    "y_test_arr_sorted = y_test[indices]\n",
    "rel_err_perc_sorted = relative_error_percentage[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(x=y_test_arr_sorted, y=rel_err_perc_sorted)\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='True remaining useful life [rotations]',\n",
    "    yaxis_title='Relative model error [%]',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Conclsions\n",
    "\n",
    "Performance of trained algorithm is hardly satisfactory. This experiment is considered unsuccessful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('bearing-rul-pred-final-aCjVDHeQ-py3.9')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "174070ce2a18601af1caccf052c3bdaa47aacc86b56acb884c173f5cfb027487"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
